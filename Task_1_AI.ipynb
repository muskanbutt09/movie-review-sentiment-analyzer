{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0D7Mw3APfCs",
        "outputId": "8b20c8bf-ec2d-4336-cfbb-467b44929481"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn nltk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca47de03"
      },
      "source": [
        "# Vectorize the preprocessed texts\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(processed_texts)\n",
        "y = labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82c1451d",
        "outputId": "44373459-f31f-4ea9-cbfb-299a139764ce"
      },
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd1d7482"
      },
      "source": [
        "# Preprocess the training texts\n",
        "processed_texts = [preprocess_text(text) for text in texts]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d06c1014"
      },
      "source": [
        "# Preprocess the training texts\n",
        "processed_texts = [preprocess_text(text) for text in texts]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "98bc7a3f",
        "outputId": "e624babd-c4e5-444e-e8a5-54348ba9c155"
      },
      "source": [
        "# Label mapping\n",
        "label_map = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
        "\n",
        "# Counters for bonus\n",
        "positive_count = 0\n",
        "negative_count = 0\n",
        "neutral_count = 0\n",
        "\n",
        "# File for logging (bonus)\n",
        "log_file = \"classification_results.txt\"\n",
        "\n",
        "print(\"Enter text to classify (type 'exit' to stop):\")\n",
        "\n",
        "while True:\n",
        "    user_input = input()\n",
        "    if user_input.lower() == 'exit':\n",
        "        break\n",
        "\n",
        "    # Preprocess\n",
        "    processed_input = preprocess_text(user_input)\n",
        "\n",
        "    # Vectorize (use the same vectorizer)\n",
        "    input_vector = vectorizer.transform([processed_input])\n",
        "\n",
        "    # Predict\n",
        "    prediction = classifier.predict(input_vector)[0]\n",
        "    sentiment = label_map[prediction]\n",
        "\n",
        "    # Display\n",
        "    print(f\"Sentiment: {sentiment}\")\n",
        "\n",
        "    # Bonus: Update counters\n",
        "    if prediction == 2:\n",
        "        positive_count += 1\n",
        "    elif prediction == 0:\n",
        "        negative_count += 1\n",
        "    else:\n",
        "        neutral_count += 1\n",
        "\n",
        "    # Bonus: Log to file\n",
        "    with open(log_file, 'a') as f:\n",
        "        f.write(f\"Input: {user_input}\\nSentiment: {sentiment}\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter text to classify (type 'exit' to stop):\n",
            "'Exit\"\n",
            "Sentiment: Negative\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3333195064.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dee9a83c",
        "outputId": "62a0756f-0955-49d9-aabc-542a61eb64e9"
      },
      "source": [
        "# Display summary\n",
        "print(\"\\nSummary:\")\n",
        "print(f\"Positive inputs: {positive_count}\")\n",
        "print(f\"Negative inputs: {negative_count}\")\n",
        "print(f\"Neutral inputs: {neutral_count}\")\n",
        "print(f\"Results saved to {log_file}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary:\n",
            "Positive inputs: 0\n",
            "Negative inputs: 1\n",
            "Neutral inputs: 0\n",
            "Results saved to classification_results.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ae049ce",
        "outputId": "51f3e051-ce01-4d1e-9366-6c6afb78c25f"
      },
      "source": [
        "print(f\"Positive count: {positive_count}\")\n",
        "print(f\"Negative count: {negative_count}\")\n",
        "print(f\"Neutral count: {neutral_count}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive count: 0\n",
            "Negative count: 1\n",
            "Neutral count: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b70fbea1",
        "outputId": "fee3a5c2-f280-435c-ca8c-fabc2b190469"
      },
      "source": [
        "# Vectorize the text (convert to numbers)\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(processed_texts)\n",
        "\n",
        "# Train the classifier\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(X, labels)\n",
        "\n",
        "# Optional: Test accuracy on the same data (for demo; in real, use separate test set)\n",
        "predictions = classifier.predict(X)\n",
        "print(\"Training Accuracy:\", accuracy_score(labels, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "678b285a"
      },
      "source": [
        "def preprocess_text(text):\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Tokenize\n",
        "    tokens = word_tokenize(text)\n",
        "    # Remove stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    # Join back to string\n",
        "    return ' '.join(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8247a701"
      },
      "source": [
        "# Custom dataset: texts and labels (0: Negative, 1: Neutral, 2: Positive)\n",
        "texts = [\n",
        "    \"I love this product!\",  # Positive\n",
        "    \"This is the best day ever.\",  # Positive\n",
        "    \"I'm so happy with the service.\",  # Positive\n",
        "    \"Great job, team!\",  # Positive\n",
        "    \"I enjoyed the movie a lot.\",  # Positive\n",
        "    \"This is terrible.\",  # Negative\n",
        "    \"I hate waiting in lines.\",  # Negative\n",
        "    \"The food was awful.\",  # Negative\n",
        "    \"I'm disappointed with the quality.\",  # Negative\n",
        "    \"This experience was bad.\",  # Negative\n",
        "    \"The weather is okay.\",  # Neutral\n",
        "    \"It's just average.\",  # Neutral\n",
        "    \"Nothing special here.\",  # Neutral\n",
        "    \"The book is fine.\",  # Neutral\n",
        "    \"I have no strong opinion.\",  # Neutral\n",
        "]\n",
        "\n",
        "labels = [2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]  # Corresponding labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7def15b",
        "outputId": "56b6e7a0-426e-4897-c9fc-1462d118511e"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score  # For testing your model\n",
        "\n",
        "# Download NLTK data (run once)\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}